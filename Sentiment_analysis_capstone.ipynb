{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "927f08a1-1f90-431b-8059-11a588ebb235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2492b180-74d8-46d3-89b8-fab184f02a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74f41e10-51c8-4054-816f-d887faf251a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('clean_song_data3.txt', encoding='MacRoman', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "623c0c7d-069e-437a-a90f-62e71e1ea316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def preprocess_text_column(data, column_name):\n",
    "    # Define a function to preprocess a single text\n",
    "    def preprocess_text(text):\n",
    "        # remove all numbers, punctuation, and special characters.\n",
    "        cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        \n",
    "        # convert all text to lower case to ensure consistency with analysis\n",
    "        cleaned_text = cleaned_text.lower()\n",
    "        \n",
    "        # Tokenization: splitting words into individual words or tokens\n",
    "        tokens = word_tokenize(cleaned_text)\n",
    "        \n",
    "        # remove all common words that do not hold much meaning like \"the\", \"is\", and \"and\"\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "        negation_words = set(['not', 'no', 'never', 'none', 'nobody', 'nothing', 'neither', 'nor'])\n",
    "        negated = False\n",
    "        result = []\n",
    "        for word in tokens:\n",
    "            if word in negation_words:\n",
    "                negated = not negated\n",
    "            else:\n",
    "                if negated:\n",
    "                    word = \"NOT_\" + word\n",
    "                result.append(word)\n",
    "        tokens = result\n",
    "        \n",
    "        # reduce words to their root forms\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "        \n",
    "        # Join tokens back into a single string\n",
    "        cleaned_text = ' '.join(tokens)\n",
    "        \n",
    "        return cleaned_text\n",
    "    \n",
    "    # Apply the preprocess_text function to the specified column\n",
    "    data[column_name] = data[column_name].apply(preprocess_text)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Example usage:\n",
    "# Assuming data_cleaned is your DataFrame and 'lyrics' is the column containing the lyrics\n",
    "data_cleaned = preprocess_text_column(data, 'lyrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c32b1c1f-c8d1-4534-b483-aeada257da23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned['polarity'] = data_cleaned['lyrics'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "# Concatenate the polarity column with the original DataFrame\n",
    "data_with_polarity = pd.concat([data, data_cleaned['polarity']], axis=1)\n",
    "\n",
    "# Write the DataFrame with the polarity column back to the original file\n",
    "with open('clean_song_data3.txt', 'w') as f:  # Assuming your file is tab-delimited\n",
    "    data_with_polarity.to_csv(f, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b067aae4-0465-455a-be85-ab14f108be05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
